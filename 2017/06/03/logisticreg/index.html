<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/assets/favicons/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png">
  <link rel="mask-icon" href="/assets/favicons/safari-pinned-tab.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"huisblog.cn","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>
<meta name="description" content="分类表达式分类和回归 分类问题和回归问题的形式是相似的，但它的预测值是一组有限的离散值。   分类问题的求解可以看做是找边界线（面）的过程，即拟合边界曲线（面），特征空间内的点分布在该曲线（面）分割出来的不同子空间中；   而回归问题的求解是拟合特征-预测值曲线（面），特征空间内的点分布在该曲线（面）上或者附近。  分类问题的假设表达式逻辑函数(Logistic Function or Si">
<meta property="og:type" content="article">
<meta property="og:title" content="逻辑回归(Logistic Regression)">
<meta property="og:url" content="http://huisblog.cn/2017/06/03/logisticreg/index.html">
<meta property="og:site_name" content="HuisBlog">
<meta property="og:description" content="分类表达式分类和回归 分类问题和回归问题的形式是相似的，但它的预测值是一组有限的离散值。   分类问题的求解可以看做是找边界线（面）的过程，即拟合边界曲线（面），特征空间内的点分布在该曲线（面）分割出来的不同子空间中；   而回归问题的求解是拟合特征-预测值曲线（面），特征空间内的点分布在该曲线（面）上或者附近。  分类问题的假设表达式逻辑函数(Logistic Function or Si">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2017-06-03T15:11:54.000Z">
<meta property="article:modified_time" content="2021-10-21T06:13:05.470Z">
<meta property="article:author" content="Hui Zhang">
<meta property="article:tag" content="ML">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://huisblog.cn/2017/06/03/logisticreg/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://huisblog.cn/2017/06/03/logisticreg/","path":"2017/06/03/logisticreg/","title":"逻辑回归(Logistic Regression)"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>逻辑回归(Logistic Regression) | HuisBlog</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">HuisBlog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-blogs"><a href="/" rel="section"><i class="fa fa-sticky-note fa-fw"></i>Blogs</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-huishome"><a href="http://zhanghui.ac.cn/" rel="noopener" target="_blank"><i class="fa fa-user fa-fw"></i>HuisHome</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E8%A1%A8%E8%BE%BE%E5%BC%8F"><span class="nav-number">1.</span> <span class="nav-text">分类表达式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E5%92%8C%E5%9B%9E%E5%BD%92"><span class="nav-number">1.1.</span> <span class="nav-text">分类和回归</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E7%9A%84%E5%81%87%E8%AE%BE%E8%A1%A8%E8%BE%BE%E5%BC%8F"><span class="nav-number">1.2.</span> <span class="nav-text">分类问题的假设表达式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%87%BD%E6%95%B0-Logistic-Function-or-Sigmoid-Function"><span class="nav-number">1.2.1.</span> <span class="nav-text">逻辑函数(Logistic Function or Sigmoid Function)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%81%87%E8%AE%BE%E5%87%BD%E6%95%B0%E7%9A%84%E7%89%A9%E7%90%86%E6%84%8F%E4%B9%89"><span class="nav-number">1.2.2.</span> <span class="nav-text">假设函数的物理意义</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%A4%E5%AE%9A%E8%BE%B9%E7%95%8C-Decision-Boundary"><span class="nav-number">1.3.</span> <span class="nav-text">判定边界(Decision Boundary)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.</span> <span class="nav-text">逻辑回归模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">2.1.</span> <span class="nav-text">损失函数和梯度下降</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">2.1.1.</span> <span class="nav-text">损失函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">2.1.2.</span> <span class="nav-text">梯度下降</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95"><span class="nav-number">2.1.3.</span> <span class="nav-text">优化算法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88-Overfitting-%E5%92%8C%E6%AD%A3%E5%88%99%E5%8C%96-Regularization"><span class="nav-number">3.</span> <span class="nav-text">过拟合(Overfitting)和正则化(Regularization)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">3.1.</span> <span class="nav-text">线性回归的正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">3.1.1.</span> <span class="nav-text">损失函数正则化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">3.1.2.</span> <span class="nav-text">梯度下降正则化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%B3%95%E6%96%B9%E7%A8%8B%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">3.1.3.</span> <span class="nav-text">法方程正则化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">3.2.</span> <span class="nav-text">逻辑回归的正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96%E5%90%8E%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">3.2.1.</span> <span class="nav-text">正则化后的损失函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96%E5%90%8E%E7%9A%84%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">3.2.2.</span> <span class="nav-text">正则化后的梯度下降</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E5%80%BC%E5%88%86%E7%B1%BB"><span class="nav-number">4.</span> <span class="nav-text">多值分类</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Hui Zhang"
      src="/assets/avatar.jpg">
  <p class="site-author-name" itemprop="name">Hui Zhang</p>
  <div class="site-description" itemprop="description">Dream It Possible</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">60</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">25</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/HuiZhangDB" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;HuiZhangDB" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:helenzhang2015@foxmail.com" title="E-Mail → mailto:helenzhang2015@foxmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Friends
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://blog.imxcy.com/" title="http:&#x2F;&#x2F;blog.imxcy.com&#x2F;" rel="noopener" target="_blank">C.Y.Xu</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://aprilwang.me/" title="https:&#x2F;&#x2F;aprilwang.me&#x2F;" rel="noopener" target="_blank">April</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.hlyue.com/" title="https:&#x2F;&#x2F;blog.hlyue.com&#x2F;" rel="noopener" target="_blank">Richard</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.senorsen.com/links/" title="https:&#x2F;&#x2F;blog.senorsen.com&#x2F;links&#x2F;" rel="noopener" target="_blank">Senorsen</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://fujiaqi.com/" title="http:&#x2F;&#x2F;fujiaqi.com&#x2F;" rel="noopener" target="_blank">Jiaqi Fu</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://qusic.me/" title="https:&#x2F;&#x2F;qusic.me&#x2F;" rel="noopener" target="_blank">Qusic</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://imsun.net/" title="https:&#x2F;&#x2F;imsun.net&#x2F;" rel="noopener" target="_blank">Sun</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.sfu.ca/~leeaol/" title="https:&#x2F;&#x2F;www.sfu.ca&#x2F;~leeaol&#x2F;" rel="noopener" target="_blank">Leeleo3x</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://mypage.zju.edu.cn/en/zhangkejun" title="http:&#x2F;&#x2F;mypage.zju.edu.cn&#x2F;en&#x2F;zhangkejun" rel="noopener" target="_blank">Kejun Zhang</a>
        </li>
    </ul>
  </div>

        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://huisblog.cn/2017/06/03/logisticreg/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/assets/avatar.jpg">
      <meta itemprop="name" content="Hui Zhang">
      <meta itemprop="description" content="Dream It Possible">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="HuisBlog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          逻辑回归(Logistic Regression)
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2017-06-03 15:11:54" itemprop="dateCreated datePublished" datetime="2017-06-03T15:11:54+00:00">2017-06-03</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2021-10-21 06:13:05" itemprop="dateModified" datetime="2021-10-21T06:13:05+00:00">2021-10-21</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/NG-ML/" itemprop="url" rel="index"><span itemprop="name">NG_ML</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<h2 id="分类表达式"><a href="#分类表达式" class="headerlink" title="分类表达式"></a>分类表达式</h2><h3 id="分类和回归"><a href="#分类和回归" class="headerlink" title="分类和回归"></a>分类和回归</h3><ul>
<li>分类问题和回归问题的形式是相似的，但它的预测值是一组有限的离散值。  </li>
<li>分类问题的求解可以看做是找边界线（面）的过程，即拟合边界曲线（面），特征空间内的点分布在该曲线（面）分割出来的不同子空间中；  </li>
<li>而回归问题的求解是拟合特征-预测值曲线（面），特征空间内的点分布在该曲线（面）上或者附近。</li>
</ul>
<h3 id="分类问题的假设表达式"><a href="#分类问题的假设表达式" class="headerlink" title="分类问题的假设表达式"></a>分类问题的假设表达式</h3><h4 id="逻辑函数-Logistic-Function-or-Sigmoid-Function"><a href="#逻辑函数-Logistic-Function-or-Sigmoid-Function" class="headerlink" title="逻辑函数(Logistic Function or Sigmoid Function)"></a>逻辑函数(Logistic Function or Sigmoid Function)</h4><p>使用逻辑函数\(g(z)\)将预测值映射到[0, 1]区间中，使假设函数更适用于分类问题。</p>
<p>$$\begin{align}&amp;<br>h_\theta (x) = g ( \theta^T x )<br>\newline<br>\newline&amp; z = \theta^T x<br>\newline&amp; g(z) = \dfrac{1}{1 + e^{-z}}<br>\end{align}$$</p>
<span id="more"></span>

<p>逻辑函数和输入值：</p>


<p>可以注意到：</p>
<p>$$\begin{align}z=0, e^{0}=1 \Rightarrow g(z)=1/2\newline z \to \infty, e^{-\infty} \to 0 \Rightarrow g(z)=1 \newline z \to -\infty, e^{\infty}\to \infty \Rightarrow g(z)=0 \end{align}$$</p>
<h4 id="假设函数的物理意义"><a href="#假设函数的物理意义" class="headerlink" title="假设函数的物理意义"></a>假设函数的物理意义</h4><p>\(h_{\theta}(x)\)表示预测值等于1的可能性：</p>
<p>$$\begin{align}&amp;<br>h_\theta(x) = P(y=1 | x ; \theta) = 1 - P(y=0 | x ; \theta)<br>\newline&amp; P(y = 0 | x;\theta) + P(y = 1 | x ; \theta) = 1<br>\end{align}$$</p>
<h3 id="判定边界-Decision-Boundary"><a href="#判定边界-Decision-Boundary" class="headerlink" title="判定边界(Decision Boundary)"></a>判定边界(Decision Boundary)</h3><p>判定边界是指分隔开不同类特征点的曲线（面），它由\(h_{\theta}(x)\)假设函数决定。<br>例如下面这个例子（二分类）中，判定边界是直线\(x_1=5\)</p>
<p>$$\begin{align}&amp; \theta = \begin{bmatrix}5 \newline -1 \newline 0\end{bmatrix} \newline &amp; y = 1 ; if ; 5 + (-1) x_1 + 0 x_2 \geq 0 \newline &amp; 5 - x_1 \geq 0 \newline &amp; - x_1 \geq -5 \newline&amp; x_1 \leq 5 \newline \end{align}$$</p>
<p>注意逻辑函数(\(e.g. \theta^Tx\))的输入不一定是线性的，它可以是任何适合训练数据的形状，比如圆(\(e.g. z =\theta_0+\theta_1x_1^2+\theta_2x_2^2\))。</p>
<h2 id="逻辑回归模型"><a href="#逻辑回归模型" class="headerlink" title="逻辑回归模型"></a>逻辑回归模型</h2><h3 id="损失函数和梯度下降"><a href="#损失函数和梯度下降" class="headerlink" title="损失函数和梯度下降"></a>损失函数和梯度下降</h3><h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>不能直接使用之前线性回归中使用的损失函数\(J(\theta)=\frac{1}{2m}\sum_{i=0}^{i=m}(h_{\theta}(x_i)-y_i)^2\)，使用逻辑函数会导致其发生扭曲，产生许多局部最优点（极小值），换句话说就不再是凸函数了。<br>所以将损失函数修改为：</p>
<p>$$\begin{align}&amp; J(\theta) = \dfrac{1}{m} \sum_{i=1}^m \mathrm{Cost}(h_\theta(x^{(i)}),y^{(i)}) \newline &amp; \mathrm{Cost}(h_\theta(x),y) = -\log(h_\theta(x)) ; &amp; \text{if y = 1} \newline &amp; \mathrm{Cost}(h_\theta(x),y) = -\log(1-h_\theta(x)) ; &amp; \text{if y = 0}\end{align}$$</p>
<p>即：</p>
<p>$$J(\theta) = - \frac{1}{m} \displaystyle \sum_{i=1}^m [y^{(i)}\log (h_\theta (x^{(i)})) + (1 - y^{(i)})\log (1 - h_\theta(x^{(i)}))]$$</p>
<p>向量形式为：</p>
<p>$$\begin{align} &amp; h = g(X\theta)\newline &amp; J(\theta) = \frac{1}{m} \cdot \left(-y^{T}\log(h)-(1-y)^{T}\log(1-h)\right) \end{align}$$</p>
<h4 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h4><p>梯度下降的标准形式：</p>
<p>$$\begin{align}&amp; Repeat ; \lbrace \newline &amp; ; \theta_j := \theta_j - \alpha \dfrac{\partial}{\partial \theta_j}J(\theta) \newline &amp; \rbrace\end{align}$$</p>
<p>代入以上\(J(\theta)\)得到：</p>
<p>$$\begin{align} &amp; Repeat ; \lbrace \newline &amp; ; \theta_j := \theta_j - \frac{\alpha}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} \newline &amp; \rbrace \end{align}$$</p>
<p>向量形式为：</p>
<p>$$\theta := \theta - \frac{\alpha}{m} X^{T} (g(X \theta ) - \vec{y})$$</p>
<h4 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h4><p><code>Conjugate gradient</code>、 <code>BFGS</code>和<code>L-BFG</code>是梯度下降的优化算法，MATLAB有提供这几个库函数，使用这几个函数同样需要定义\(J(\theta)\)和\(\dfrac{\partial}{\partial \theta_j}J(\theta)\)。</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[jVal, gradient]</span> = <span class="title">costFunction</span><span class="params">(theta)</span></span></span><br><span class="line">  jVal = [...code to compute J(theta)...];</span><br><span class="line">  gradient = [...code to compute derivative of J(theta)...];</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>MATLAB提供了<code>fminunc()</code>函数来实现优化：</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">options = optimset(<span class="string">&#x27;GradObj&#x27;</span>, <span class="string">&#x27;on&#x27;</span>, <span class="string">&#x27;MaxIter&#x27;</span>, <span class="number">100</span>);</span><br><span class="line">initialTheta = <span class="built_in">zeros</span>(<span class="number">2</span>,<span class="number">1</span>);</span><br><span class="line">   [optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options);</span><br></pre></td></tr></table></figure>

<h2 id="过拟合-Overfitting-和正则化-Regularization"><a href="#过拟合-Overfitting-和正则化-Regularization" class="headerlink" title="过拟合(Overfitting)和正则化(Regularization)"></a>过拟合(Overfitting)和正则化(Regularization)</h2><p><code>欠拟合(underfitting)</code>或<code>高偏差(high bias)</code>，是指假设函数不足以描述数据趋势，通常由假设函数过于简单或者特征维数太少导致；<br><code>过拟合(overfitting)</code>或<code>高方差(high variance)</code>，是指假设函数对训练集拟合良好但对测试集的通用性差，通常由于假设函数过于复杂或特征维数太高。</p>
<p>解决过拟合问题的常用方法：</p>
<ol>
<li>减少特征维数：手动选择特征、使用模型选择算法；</li>
<li><code>正则化(Regularization)</code>：保留所有特征，但减小参数\(\theta_j\)的量级；正则化在有许多弱相关特征(slightly useful features)的时候很有用。</li>
</ol>
<h3 id="线性回归的正则化"><a href="#线性回归的正则化" class="headerlink" title="线性回归的正则化"></a>线性回归的正则化</h3><h4 id="损失函数正则化"><a href="#损失函数正则化" class="headerlink" title="损失函数正则化"></a>损失函数正则化</h4><p>正则化其实就是通过增加参数在损失函数中的影响来减弱其最后在假设函数中的权重：<br>例如，对于假设函数\(\theta_0 + \theta_1x + \theta_2x^2 + \theta_3x^3 + \theta_4x^4\)，如果想让它变得更加“二次方”，即排除\(\theta_3x^3 \)和\(\theta_4x^4\)的影响，可以通过修改损失函数来实现：</p>
<p>$$min_\theta\ \dfrac{1}{2m}\sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2 + 1000\cdot\theta_3^2 + 1000\cdot\theta_4^2$$</p>
<p>正则化所有参数（除了\(\theta_0\)）：</p>
<p>$$min_\theta\ \dfrac{1}{2m}\  \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2 + \lambda\ \sum_{j=1}^n \theta_j^2$$</p>
<p>其中\(\lambda\)是<code>正则化系数(regularization parameter)</code>，\(\lambda\)越大，拟合曲线越平滑，但要注意的是\(\lambda\)过大可能导致欠拟合。</p>
<h4 id="梯度下降正则化"><a href="#梯度下降正则化" class="headerlink" title="梯度下降正则化"></a>梯度下降正则化</h4><p>对于线性回归而言，正则化后的梯度下降：</p>
<p>$$\begin{align} &amp; \text{Repeat}\ \lbrace \newline &amp; \ \ \ \ \theta_0 := \theta_0 - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \newline &amp; \ \ \ \ \theta_j := \theta_j - \alpha\ \left[ \left( \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \right) + \frac{\lambda}{m}\theta_j \right] &amp;\ \ \ \ \ \ \ \ \ \ j \in \lbrace 1,2…n\rbrace\newline &amp; \rbrace \end{align}$$ </p>
<h4 id="法方程正则化"><a href="#法方程正则化" class="headerlink" title="法方程正则化"></a>法方程正则化</h4><p>正则化后的法方程可以写为：</p>
<p>$$\begin{align}&amp; \theta = \left( X^TX + \lambda \cdot L \right)^{-1} X^Ty \newline&amp; \text{where}\ \ L = \begin{bmatrix} 0 &amp; &amp; &amp; &amp; \newline &amp; 1 &amp; &amp; &amp; \newline &amp; &amp; 1 &amp; &amp; \newline &amp; &amp; &amp; \ddots &amp; \newline &amp; &amp; &amp; &amp; 1 \newline\end{bmatrix}\end{align}$$</p>
<p>要注意梯度下降中的下标\(j\)是从1开始的，同样，法方程中\(\lambda(1,1)=0\)，这是因为截取项\(\theta_0\)是不需要正则化的。</p>
<h3 id="逻辑回归的正则化"><a href="#逻辑回归的正则化" class="headerlink" title="逻辑回归的正则化"></a>逻辑回归的正则化</h3><h4 id="正则化后的损失函数"><a href="#正则化后的损失函数" class="headerlink" title="正则化后的损失函数"></a>正则化后的损失函数</h4><p>逻辑回归的损失函数加上正则化项：</p>
<p>$$J(\theta) = - \frac{1}{m} \sum_{i=1}^m [ y^{(i)}\ \log (h_\theta (x^{(i)})) + (1 - y^{(i)})\ \log (1 - h_\theta(x^{(i)}))] + \frac{\lambda}{2m}\sum_{j=1}^n \theta_j^2$$</p>
<p>注意\(\sum_{j=1}^n \theta_j^2\)下标从1开始，在梯度下降中也要特别注意\(\theta_0\)的更新。</p>
<h4 id="正则化后的梯度下降"><a href="#正则化后的梯度下降" class="headerlink" title="正则化后的梯度下降"></a>正则化后的梯度下降</h4><p>$$\begin{align} &amp; \text{Repeat}\ \lbrace \newline &amp; \ \ \ \ \theta_0 := \theta_0 - \alpha\ \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_0^{(i)} \newline &amp; \ \ \ \ \theta_j := \theta_j - \alpha\ \left[ \left( \frac{1}{m}\ \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \right) + \frac{\lambda}{m}\theta_j \right] &amp;\ \ \ \ \ \ \ \ \ \ j \in \lbrace 1,2…n\rbrace\newline &amp; \rbrace \end{align}$$ </p>
<h2 id="多值分类"><a href="#多值分类" class="headerlink" title="多值分类"></a>多值分类</h2><p>当预测分类值有多个，如\(y={0,1,2,…,n}\)时，可以将其看做\(n+1\)个二值分类问题：对于每一类，将其看做一类而其他所有的看做一类。</p>
<p>$$\begin{align}&amp; y \in \lbrace0, 1 … n\rbrace \newline&amp; h_\theta^{(0)}(x) = P(y = 0 | x ; \theta) \newline&amp; h_\theta^{(1)}(x) = P(y = 1 | x ; \theta) \newline&amp; \cdots \newline&amp; h_\theta^{(n)}(x) = P(y = n | x ; \theta) \newline&amp; \mathrm{prediction} = \max_i( h_\theta ^{(i)}(x) )\newline\end{align}$$</p>
<ol>
<li>训练时，对每一类做二值逻辑回归分类器训练；</li>
<li>预测时，计算每类的预测值，最大的为结果。</li>
</ol>
<p>举个例子（3值分类）：</p>





    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/ML/" rel="tag"># ML</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2017/06/03/multilinear/" rel="prev" title="多变量线性回归">
                  <i class="fa fa-chevron-left"></i> 多变量线性回归
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2017/06/15/neuralnetwork/" rel="next" title="神经网络(Neural Networks)">
                  神经网络(Neural Networks) <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hui Zhang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  

  <script class="next-config" data-name="pdf" type="application/json">{"object_url":{"url":"https://cdn.jsdelivr.net/npm/pdfobject@2.2.6/pdfobject.min.js","integrity":"sha256-77geM50MfxCD17eqyJR+Dag1svjJOLN+BJ2F/DMqMEY="},"url":"/lib/pdf/web/viewer.html"}</script>
  <script src="/js/third-party/tags/pdf.js"></script>




  





</body>
</html>
